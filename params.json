{"name":"Lucene-example","tagline":"Hello world usging apache lucene.","body":"# lucene-example\r\nHello world usging apache lucene.\r\nThis is a maven based project contains Lucene basics.\r\nApache Lucen is a full text-search library for java which helps\r\nyou add search capability to your application/website.\r\n\r\n# Few Terminology need to remember.\r\n## Index\r\n\r\nLucene uses index called an inverted index, because it inverts\r\na page-centric data structure in class room (Student Name->roll number) to a keyword-centric\r\ndata structure (word->pages).\r\nAt time of index we can store the field depend upn the usages find that index will be easier.\r\n<code>\r\nField.Store.YES\r\n</code>\r\n\r\n\r\nIf we are storing index using StringField in document then while quering It shot be exact match.\r\nString field dos not work on tokinezier so it require exact match.\r\n\r\nIn case of TextField it works on toknizing the element so it doesnot require the exact macth,\r\nbut be carefull it doesnot reconize english gramattical sentence like A, An The etc..\r\n\r\n\r\n## Analyzer Class: Parsing the Documents\r\nMost likely, the data that you want to index by Lucene is plain text English. The job of Analyzer is to \"parse\" each field of your data into indexable \"tokens\" or keywords. Several types of analyzers are provided out of the box. Table 1 shows some of the more interesting ones.\r\n\r\nTable 1 Lucene analyzers.\r\n\r\n| Analyzer          | Description           | \r\n| -------------     |:-------------:|\r\n| StandardAnalyzer  | A sophisticated general-purpose analyzer | \r\n| WhitespaceAnalyzer| A very simple analyzer that just separates tokens using white space.     |\r\n| StopAnalyzer      |Removes common English words that are not usually useful for indexing.     |\r\n| SnowballAnalyzer  |An interesting experimental analyzer that works on word roots (a search on rain should also return entries with raining, rained, and so on).| \r\n\r\n\r\n## Document\r\n\r\nAn index consists of one or more Documents.\r\nIndexing involves adding Documents to an IndexWriter,\r\nand searching involves retrieving Documents from an index via an IndexSearcher. \r\n\r\nMore precisely, to add a field to a document, you create a new instance of the Field class, which can be either a StringField or a TextField (the difference between the two will be explained shortly). A field object takes the following three parameters:\r\n\r\n    Field name: This is the name of the field. In the above example, they are \"id\" and \"description\".\r\n    Field value: This is the value of the field. In the above example, they are \"Hotel-1345\" and \"A beautiful hotel\". A value can be a String like our example or a Reader if the object to be indexed is a file.\r\n    Storage flag: The third parameter specifies whether the actual value of the field needs to be stored in the lucene index or it can be discarded after it is indexed. Storing the value is useful if you need the value later, like you want to display it in the search result list or you use the value to look up a tuple from a database table, for example. If the value must be stored, use Field.Store.YES. You can also use Field.Store.COMPRESS for large documents or binary value fields. If you don't need to store the value, use Field.Store.NO.\r\n\r\nStringField vs TextField: In the above example, the \"id\" field contains the ID of the hotel, which is a single atomic value. In contrast, the \"description\" field contains an English text, which should be parsed (or \"tokenized\") into a set of words for indexing. Use StringField for a field with an atomic value that should not be tokenized. Use TextField for a field that needs to be tokenized into a set of words. \r\n\r\n\r\n","google":"","note":"Don't delete this file! It's used internally to help with page regeneration."}